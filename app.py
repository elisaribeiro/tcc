import streamlit as st
import time

# main.py
import os
import asyncio
from dotenv import load_dotenv
import json
from typing import List, Dict, Any # Importar tipos para o hist√≥rico de chat

# Importa as fun√ß√µes de alto n√≠vel dos seus m√≥dulos separados
from browser_agent import run_fomento_search_agent
from indexador_pdf import process_pdfs_into_documents # Usando o nome que voc√™ forneceu
from rag import HuggingFaceEmbedding, perguntar_openai, retrieve_documents # Usando o nome que voc√™ forneceu
from langchain_chroma import Chroma
from langchain_core.documents import Document

# Importa a fun√ß√£o de download
from download_manager import download_pdfs_from_editals_json

# --- Configura√ß√µes Iniciais ---
load_dotenv()
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# --- Inicializa√ß√£o Global da Vector Store e Embedding ---
embedding_function = HuggingFaceEmbedding()
vectorstore = Chroma(
    embedding_function=embedding_function,
    persist_directory="chroma"
)

def start_qa_session(user_question):
    print("\n--- Inciando sess√£o de Perguntas e Respostas. Digite 'voltar' para retornar ao menu principal. ---")
    
    chat_history: List[Dict[str, str]] = [] # NOVO: Inicializa o hist√≥rico de chat para a sess√£o

    # user_question = input("\nSua pergunta (ou 'voltar'): ").strip()
    # if user_question.lower() == 'voltar':
    #     print("Retornando ao menu principal.")
    #     break

    docs = retrieve_documents(user_question, vectorstore)

    MAX_CHARS = 80000 
    contexto = ""
    if not docs:
        response_content = "Desculpe, n√£o encontrei informa√ß√µes relevantes para sua pergunta nos editais indexados. Por favor, tente indexar mais dados."
    else:
        for doc in docs:
            if len(contexto) + len(doc.page_content) + 2 <= MAX_CHARS:
                contexto += doc.page_content + "\n\n"
            else:
                print(f"‚ö†Ô∏è Limite de caracteres do contexto atingido. Pulando documentos restantes.")
                break
        
        try:
            # Passa o hist√≥rico de chat para a fun√ß√£o perguntar_openai
            response_content = perguntar_openai(user_question, contexto, chat_history=chat_history) 
        except Exception as e:
            response_content = f"Ocorreu um erro ao gerar a resposta: {e}. Por favor, verifique sua chave da API ou o status do servi√ßo do LLM."
    
    # # Adiciona a resposta do assistente ao hist√≥rico de chat
    # chat_history.append({"role": "assistant", "content": response_content})
    return response_content
    # print("\nüìå Resposta do modelo:\n", response_content)



# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
# Define o t√≠tulo da p√°gina, o √≠cone e o layout.
st.set_page_config(page_title="Meu Chatbot", page_icon="ü§ñ", layout="centered")

# --- FUN√á√ÉO DE RESPOSTA DO BOT ---
# Esta √© uma fun√ß√£o de exemplo. Em um caso real, voc√™ faria uma chamada
# para uma API de um modelo de linguagem (como a API do Gemini, OpenAI, etc.).
def get_bot_response(user_input):
    """Gera uma resposta simples do bot."""
    # Simula um "pensamento" do bot por um breve momento
    time.sleep(1) 
    return f"Recebi sua mensagem! Voc√™ disse: '{user_input}'"

# --- Fun√ß√£o Auxiliar para Adicionar Documentos √† Vector Store ---
def add_documents_to_vectorstore(documents_to_add: list[Document]):
    if documents_to_add:
        print(f"Adicionando {len(documents_to_add)} documentos √† Vector Store...")
        vectorstore.add_documents(documents_to_add)
        print(f"**{len(documents_to_add)}** documentos adicionados e persistidos com sucesso na Vector Store.")
    else:
        print("Nenhum documento para adicionar √† Vector Store.")

async def chama_browser_use():
    online_grants_data = await run_fomento_search_agent()
    if online_grants_data:
        print(f"**{len(online_grants_data)}** editais abertos (incluindo novos e existentes) agora est√£o no cache.")
        
        # --- CHAMADA CORRIGIDA PARA BAIXAR PDFs ---
        print("\nIniciando automaticamente o download dos PDFs dos editais encontrados...")
        download_dir = "pdfs_baixados"
        # <<< CORRE√á√ÉO AQUI: Receber a lista de caminhos diretamente >>>
        downloaded_pdf_paths: List[str] = download_pdfs_from_editals_json(online_grants_data, download_dir)
        
        print(f"Total de PDFs baixados nesta execu√ß√£o: {len(downloaded_pdf_paths)}")
        # --- FIM CHAMADA ---

        # Processa APENAS os PDFs que foram baixados NESTA execu√ß√£o
        if downloaded_pdf_paths:
            downloaded_pdf_chunks = process_pdfs_into_documents(downloaded_pdf_paths)
            add_documents_to_vectorstore(downloaded_pdf_chunks)
        else:
            print("Nenhum PDF baixado para indexar a partir dos editais online.")
        
        print("\nEditais online atualizados, baixados (se aplic√°vel) e indexados. Voc√™ pode fazer perguntas agora.")
    else:
        print("\nNenhum edital online aberto foi encontrado ou permaneceu no cache ap√≥s a atualiza√ß√£o.")
        print("N√£o foi poss√≠vel atualizar o √≠ndice com novos editais online.")

# --- INICIALIZA√á√ÉO DO ESTADO DA SESS√ÉO ---
# O st.session_state √© um dicion√°rio que persiste entre os reruns do script.
# Usamos para manter o estado da nossa aplica√ß√£o.

# Verifica se o hist√≥rico de chats j√° existe no estado da sess√£o.
if "chat_history" not in st.session_state:
    # Se n√£o existir, inicializa com um dicion√°rio vazio.
    st.session_state.chat_history = {}

# Verifica se um chat ativo est√° definido.
if "current_chat_id" not in st.session_state:
    # Se n√£o, cria um novo chat ao iniciar a aplica√ß√£o.
    initial_chat_id = f"chat_{int(time.time())}"
    st.session_state.current_chat_id = initial_chat_id
    # Cada chat √© uma lista de mensagens. Come√ßamos com uma mensagem do assistente.
    st.session_state.chat_history[initial_chat_id] = [
        {"role": "assistant", "content": "Ol√°! Como posso te ajudar hoje?"}
    ]

# --- L√ìGICA DA BARRA LATERAL (SIDEBAR) ---
with st.sidebar:
    st.title("Atualizar Editais")
    if st.button("üîÑ Atualizar Editais"):
        # Inicia o processo de atualiza√ß√£o dos editais
        with st.spinner("Atualizando editais..."):
            asyncio.run(chama_browser_use())
        st.success("Editais atualizados com sucesso!")

    st.title("Hist√≥rico de Conversas")

    # Bot√£o para criar uma nova conversa
    if st.button("‚ûï Nova Conversa"):
        # Cria um ID √∫nico para a nova conversa baseado no tempo atual
        new_chat_id = f"chat_{int(time.time())}"
        # Define este novo ID como o chat atual
        st.session_state.current_chat_id = new_chat_id
        # Inicializa a nova conversa com uma mensagem de boas-vindas
        st.session_state.chat_history[new_chat_id] = [
            {"role": "assistant", "content": "Nova conversa iniciada. Mande sua pergunta!"}
        ]
        # For√ßa o rerun do script para atualizar a interface
        st.rerun()

    st.write("---") # Linha divis√≥ria

    # Exibe as conversas anteriores como bot√µes na barra lateral
    # Itera sobre as chaves (IDs dos chats) em ordem reversa (mais recentes primeiro)
    for chat_id in reversed(list(st.session_state.chat_history.keys())):
        # Pega a primeira mensagem do usu√°rio para usar como t√≠tulo do chat
        # Se n√£o houver mensagem do usu√°rio ainda, usa um t√≠tulo padr√£o.
        messages = st.session_state.chat_history[chat_id]
        first_user_message = next((msg["content"] for msg in messages if msg["role"] == "user"), "Nova Conversa...")
        
        # Cria um bot√£o com um trecho da primeira mensagem
        if st.button(first_user_message[:30] + "...", key=f"btn_{chat_id}", use_container_width=True):
            # Se o bot√£o for clicado, define o ID do chat correspondente como o chat atual
            st.session_state.current_chat_id = chat_id
            # For√ßa o rerun para exibir o chat selecionado
            st.rerun()

    with st.expander("Configura√ß√µes Avan√ßadas", expanded=False):
        st.write("API do OpenRouter")
        api_key = st.text_input("Chave da API", type="password", key="api_key_input")
        os.environ["OPENROUTER_API_KEY"] = api_key

# --- L√ìGICA DA JANELA PRINCIPAL DO CHAT ---

st.title("ü§ñ Meu Chatbot Pessoal")
st.caption("Um aplicativo de chat simples usando Streamlit")

# Obt√©m o ID do chat atual
current_chat_id = st.session_state.current_chat_id

# Obt√©m a lista de mensagens para a conversa atual
current_messages = st.session_state.chat_history[current_chat_id]

# Exibe as mensagens do hist√≥rico da conversa atual
# O st.chat_message cria um container de mensagem com avatar
for message in current_messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- INPUT DO USU√ÅRIO ---
# O st.chat_input cria um campo de entrada fixo na parte inferior da tela.
# A vari√°vel 'prompt' conter√° o texto digitado pelo usu√°rio quando ele pressionar Enter.
if prompt := st.chat_input("Digite sua mensagem aqui..."):
    # 1. Adiciona a mensagem do usu√°rio ao hist√≥rico da conversa atual
    current_messages.append({"role": "user", "content": prompt})

    # 2. Exibe a mensagem do usu√°rio na tela imediatamente
    with st.chat_message("user"):
        st.markdown(prompt)

    # 3. Gera e exibe a resposta do bot
    with st.chat_message("assistant"):
        # Mostra um spinner enquanto o bot "pensa"
        with st.spinner("Pensando..."):
            response = start_qa_session(prompt)
        # Exibe a resposta
        st.markdown(response)

    # 4. Adiciona a resposta do bot ao hist√≥rico da conversa
    current_messages.append({"role": "assistant", "content": response})